{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc7170f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d289f041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO_GT</th>\n",
       "      <th>PT08_S1_CO</th>\n",
       "      <th>NMHC_GT</th>\n",
       "      <th>C6H6_GT</th>\n",
       "      <th>PT08_S2_NMHC</th>\n",
       "      <th>Nox_GT</th>\n",
       "      <th>PT08_S3_Nox</th>\n",
       "      <th>NO2_GT</th>\n",
       "      <th>PT08_S4_NO2</th>\n",
       "      <th>PT08_S5_O3</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>CO_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/23/2004</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2008</td>\n",
       "      <td>-200</td>\n",
       "      <td>50.6</td>\n",
       "      <td>1980</td>\n",
       "      <td>1389</td>\n",
       "      <td>325</td>\n",
       "      <td>220</td>\n",
       "      <td>2562</td>\n",
       "      <td>2342</td>\n",
       "      <td>12.4</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1.0741</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/23/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1918</td>\n",
       "      <td>-200</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1958</td>\n",
       "      <td>1358</td>\n",
       "      <td>335</td>\n",
       "      <td>190</td>\n",
       "      <td>2477</td>\n",
       "      <td>2237</td>\n",
       "      <td>11.5</td>\n",
       "      <td>76.2</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/17/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1802</td>\n",
       "      <td>-200</td>\n",
       "      <td>47.7</td>\n",
       "      <td>1924</td>\n",
       "      <td>748</td>\n",
       "      <td>356</td>\n",
       "      <td>192</td>\n",
       "      <td>2235</td>\n",
       "      <td>2452</td>\n",
       "      <td>13.7</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/23/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1982</td>\n",
       "      <td>-200</td>\n",
       "      <td>49.5</td>\n",
       "      <td>1959</td>\n",
       "      <td>1369</td>\n",
       "      <td>322</td>\n",
       "      <td>227</td>\n",
       "      <td>2536</td>\n",
       "      <td>2386</td>\n",
       "      <td>13.2</td>\n",
       "      <td>72.6</td>\n",
       "      <td>1.0936</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/26/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1956</td>\n",
       "      <td>-200</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1877</td>\n",
       "      <td>1389</td>\n",
       "      <td>347</td>\n",
       "      <td>255</td>\n",
       "      <td>2338</td>\n",
       "      <td>2465</td>\n",
       "      <td>15.5</td>\n",
       "      <td>62.8</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO_GT  PT08_S1_CO  NMHC_GT  C6H6_GT  PT08_S2_NMHC  \\\n",
       "0  11/23/2004  19:00:00   11.9        2008     -200     50.6          1980   \n",
       "1  11/23/2004  20:00:00   11.5        1918     -200     49.4          1958   \n",
       "2  11/17/2004  18:00:00   10.2        1802     -200     47.7          1924   \n",
       "3  11/23/2004  18:00:00   10.2        1982     -200     49.5          1959   \n",
       "4  11/26/2004  18:00:00   10.1        1956     -200     45.2          1877   \n",
       "\n",
       "   Nox_GT  PT08_S3_Nox  NO2_GT  PT08_S4_NO2  PT08_S5_O3     T    RH      AH  \\\n",
       "0    1389          325     220         2562        2342  12.4  74.7  1.0741   \n",
       "1    1358          335     190         2477        2237  11.5  76.2  1.0324   \n",
       "2     748          356     192         2235        2452  13.7  52.8  0.8244   \n",
       "3    1369          322     227         2536        2386  13.2  72.6  1.0936   \n",
       "4    1389          347     255         2338        2465  15.5  62.8  1.0979   \n",
       "\n",
       "    CO_level  \n",
       "0  Very High  \n",
       "1  Very High  \n",
       "2  Very High  \n",
       "3  Very High  \n",
       "4  Very High  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/tarsur909/Documents/PythonStuff/AirQualityUCI.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4af60170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO_GT</th>\n",
       "      <th>PT08_S1_CO</th>\n",
       "      <th>NMHC_GT</th>\n",
       "      <th>C6H6_GT</th>\n",
       "      <th>PT08_S2_NMHC</th>\n",
       "      <th>Nox_GT</th>\n",
       "      <th>PT08_S3_Nox</th>\n",
       "      <th>NO2_GT</th>\n",
       "      <th>PT08_S4_NO2</th>\n",
       "      <th>PT08_S5_O3</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>CO_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2004-03-10</th>\n",
       "      <th>2232</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046</td>\n",
       "      <td>166</td>\n",
       "      <td>1056</td>\n",
       "      <td>113</td>\n",
       "      <td>1692</td>\n",
       "      <td>1268</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>112</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955</td>\n",
       "      <td>103</td>\n",
       "      <td>1174</td>\n",
       "      <td>92</td>\n",
       "      <td>1559</td>\n",
       "      <td>972</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402</td>\n",
       "      <td>88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939</td>\n",
       "      <td>131</td>\n",
       "      <td>1140</td>\n",
       "      <td>114</td>\n",
       "      <td>1555</td>\n",
       "      <td>1074</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376</td>\n",
       "      <td>80</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948</td>\n",
       "      <td>172</td>\n",
       "      <td>1092</td>\n",
       "      <td>122</td>\n",
       "      <td>1584</td>\n",
       "      <td>1203</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272</td>\n",
       "      <td>51</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836</td>\n",
       "      <td>131</td>\n",
       "      <td>1205</td>\n",
       "      <td>116</td>\n",
       "      <td>1490</td>\n",
       "      <td>1110</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Time  CO_GT  PT08_S1_CO  NMHC_GT  C6H6_GT  \\\n",
       "Date                                                                        \n",
       "2004-03-10 2232 2004-03-10  18:00:00    2.6        1360      150     11.9   \n",
       "           3328 2004-03-10  19:00:00    2.0        1292      112      9.4   \n",
       "           2908 2004-03-10  20:00:00    2.2        1402       88      9.0   \n",
       "           2909 2004-03-10  21:00:00    2.2        1376       80      9.2   \n",
       "           4224 2004-03-10  22:00:00    1.6        1272       51      6.5   \n",
       "\n",
       "                 PT08_S2_NMHC  Nox_GT  PT08_S3_Nox  NO2_GT  PT08_S4_NO2  \\\n",
       "Date                                                                      \n",
       "2004-03-10 2232          1046     166         1056     113         1692   \n",
       "           3328           955     103         1174      92         1559   \n",
       "           2908           939     131         1140     114         1555   \n",
       "           2909           948     172         1092     122         1584   \n",
       "           4224           836     131         1205     116         1490   \n",
       "\n",
       "                 PT08_S5_O3     T    RH      AH CO_level  \n",
       "Date                                                      \n",
       "2004-03-10 2232        1268  13.6  48.9  0.7578     High  \n",
       "           3328         972  13.3  47.7  0.7255     High  \n",
       "           2908        1074  11.9  54.0  0.7502     High  \n",
       "           2909        1203  11.0  60.0  0.7867     High  \n",
       "           4224        1110  11.2  59.6  0.7888     High  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='Date')\n",
    "df = df.groupby('Date').apply(lambda x: x.sort_values('Time'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ee1b8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "f_lst = ['PT08_S1_CO', 'NMHC_GT', 'C6H6_GT', 'NO2_GT']\n",
    "for k in range(len(f_lst)):\n",
    "    df[f_lst[k]] = scaler.fit_transform(np.array(df[f_lst[k]]).reshape(-1, 1))\n",
    "\n",
    "\n",
    "X = np.array(df[['PT08_S1_CO', 'NMHC_GT', 'C6H6_GT']])\n",
    "y = np.array(df[['NO2_GT']]).flatten()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "46563789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "X_train = Variable(torch.tensor(X_train))\n",
    "X_test = Variable(torch.tensor(X_test))\n",
    "y_train = Variable(torch.tensor(y_train))\n",
    "y_test = Variable(torch.tensor(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f75b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d21d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first= True,dropout = 0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, self.hidden_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, self.hidden_size))\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        out = self.dropout(out)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bfec633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 1:57:22&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarsur909/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([7485])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.31724 valid loss:  0.21017 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarsur909/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1872])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.25215 valid loss:  0.14351 \n",
      "Epoch: 3, loss: 0.12228 valid loss:  0.07720 \n",
      "Epoch: 4, loss: 0.06417 valid loss:  0.09132 \n",
      "Epoch: 5, loss: 0.26697 valid loss:  0.05965 \n",
      "Epoch: 6, loss: 0.05604 valid loss:  0.08526 \n",
      "Epoch: 7, loss: 0.28372 valid loss:  0.11092 \n",
      "Epoch: 8, loss: 0.09350 valid loss:  0.12398 \n",
      "Epoch: 9, loss: 0.28372 valid loss:  0.13383 \n",
      "Epoch: 10, loss: 0.11560 valid loss:  0.13526 \n",
      "Epoch: 11, loss: 0.28372 valid loss:  0.13607 \n",
      "Epoch: 12, loss: 0.17854 valid loss:  0.13540 \n",
      "Epoch: 13, loss: 0.11736 valid loss:  0.12973 \n",
      "Epoch: 14, loss: 0.10948 valid loss:  0.12014 \n",
      "Epoch: 15, loss: 0.10130 valid loss:  0.10728 \n",
      "Epoch: 16, loss: 0.17330 valid loss:  0.09500 \n",
      "Epoch: 17, loss: 0.07575 valid loss:  0.08071 \n",
      "Epoch: 18, loss: 0.06516 valid loss:  0.06659 \n",
      "Epoch: 19, loss: 0.17041 valid loss:  0.05739 \n",
      "Epoch: 20, loss: 0.05786 valid loss:  0.05714 \n",
      "Epoch: 21, loss: 0.07156 valid loss:  0.05692 \n",
      "Epoch: 22, loss: 0.06792 valid loss:  0.05702 \n",
      "Epoch: 23, loss: 0.06049 valid loss:  0.06035 \n",
      "Epoch: 24, loss: 0.16948 valid loss:  0.06520 \n",
      "Epoch: 25, loss: 0.16965 valid loss:  0.06990 \n",
      "Epoch: 26, loss: 0.05685 valid loss:  0.07339 \n",
      "Epoch: 27, loss: 0.17236 valid loss:  0.07561 \n",
      "Epoch: 28, loss: 0.17231 valid loss:  0.07669 \n",
      "Epoch: 29, loss: 0.06106 valid loss:  0.07614 \n",
      "Epoch: 30, loss: 0.17195 valid loss:  0.07489 \n",
      "Epoch: 31, loss: 0.05930 valid loss:  0.07261 \n",
      "Epoch: 32, loss: 0.05819 valid loss:  0.06970 \n",
      "Epoch: 33, loss: 0.17063 valid loss:  0.06688 \n",
      "Epoch: 34, loss: 0.05576 valid loss:  0.06423 \n",
      "Epoch: 35, loss: 0.05531 valid loss:  0.06197 \n",
      "Epoch: 36, loss: 0.05532 valid loss:  0.06029 \n",
      "Epoch: 37, loss: 0.17028 valid loss:  0.05925 \n",
      "Epoch: 38, loss: 0.05649 valid loss:  0.05882 \n",
      "Epoch: 39, loss: 0.16963 valid loss:  0.05858 \n",
      "Epoch: 40, loss: 0.05660 valid loss:  0.05882 \n",
      "Epoch: 41, loss: 0.05620 valid loss:  0.05951 \n",
      "Epoch: 42, loss: 0.16964 valid loss:  0.06034 \n",
      "Epoch: 43, loss: 0.05520 valid loss:  0.06135 \n",
      "Epoch: 44, loss: 0.16959 valid loss:  0.06252 \n",
      "Epoch: 45, loss: 0.05512 valid loss:  0.06383 \n",
      "Epoch: 46, loss: 0.16936 valid loss:  0.06506 \n",
      "Epoch: 47, loss: 0.05538 valid loss:  0.06591 \n",
      "Epoch: 48, loss: 0.16978 valid loss:  0.06642 \n",
      "Epoch: 49, loss: 0.16950 valid loss:  0.06675 \n",
      "Epoch: 50, loss: 0.17022 valid loss:  0.06665 \n",
      "Epoch: 51, loss: 0.16972 valid loss:  0.06630 \n",
      "Epoch: 52, loss: 0.28372 valid loss:  0.06599 \n",
      "Epoch: 53, loss: 0.05560 valid loss:  0.06529 \n",
      "Epoch: 54, loss: 0.05556 valid loss:  0.06428 \n",
      "Epoch: 55, loss: 0.05508 valid loss:  0.06327 \n",
      "Epoch: 56, loss: 0.05502 valid loss:  0.06238 \n",
      "Epoch: 57, loss: 0.16936 valid loss:  0.06161 \n",
      "Epoch: 58, loss: 0.05516 valid loss:  0.06112 \n",
      "Epoch: 59, loss: 0.05514 valid loss:  0.06088 \n",
      "Epoch: 60, loss: 0.28372 valid loss:  0.06065 \n",
      "Epoch: 61, loss: 0.16942 valid loss:  0.06053 \n",
      "Epoch: 62, loss: 0.05521 valid loss:  0.06065 \n",
      "Epoch: 63, loss: 0.05522 valid loss:  0.06098 \n",
      "Epoch: 64, loss: 0.28372 valid loss:  0.06129 \n",
      "Epoch: 65, loss: 0.05502 valid loss:  0.06165 \n",
      "Epoch: 66, loss: 0.05522 valid loss:  0.06220 \n",
      "Epoch: 67, loss: 0.05504 valid loss:  0.06280 \n",
      "Epoch: 68, loss: 0.05503 valid loss:  0.06337 \n",
      "Epoch: 69, loss: 0.05506 valid loss:  0.06376 \n",
      "Epoch: 70, loss: 0.16940 valid loss:  0.06404 \n",
      "Epoch: 71, loss: 0.16940 valid loss:  0.06422 \n",
      "Epoch: 72, loss: 0.05532 valid loss:  0.06406 \n",
      "Epoch: 73, loss: 0.05505 valid loss:  0.06378 \n",
      "Epoch: 74, loss: 0.05512 valid loss:  0.06334 \n",
      "Epoch: 75, loss: 0.16952 valid loss:  0.06276 \n",
      "Epoch: 76, loss: 0.16948 valid loss:  0.06211 \n",
      "Epoch: 77, loss: 0.05504 valid loss:  0.06154 \n",
      "Epoch: 78, loss: 0.16941 valid loss:  0.06111 \n",
      "Epoch: 79, loss: 0.16942 valid loss:  0.06084 \n",
      "Epoch: 80, loss: 0.28372 valid loss:  0.06060 \n",
      "Epoch: 81, loss: 0.05537 valid loss:  0.06071 \n",
      "Epoch: 82, loss: 0.16941 valid loss:  0.06089 \n",
      "Epoch: 83, loss: 0.16938 valid loss:  0.06112 \n",
      "Epoch: 84, loss: 0.05506 valid loss:  0.06146 \n",
      "Epoch: 85, loss: 0.05526 valid loss:  0.06200 \n",
      "Epoch: 86, loss: 0.28372 valid loss:  0.06251 \n",
      "Epoch: 87, loss: 0.05506 valid loss:  0.06298 \n",
      "Epoch: 88, loss: 0.16942 valid loss:  0.06331 \n",
      "Epoch: 89, loss: 0.05510 valid loss:  0.06358 \n",
      "Epoch: 90, loss: 0.05509 valid loss:  0.06364 \n",
      "Epoch: 91, loss: 0.05506 valid loss:  0.06359 \n",
      "Epoch: 92, loss: 0.05504 valid loss:  0.06349 \n",
      "Epoch: 93, loss: 0.05509 valid loss:  0.06351 \n",
      "Epoch: 94, loss: 0.16964 valid loss:  0.06325 \n",
      "Epoch: 95, loss: 0.05513 valid loss:  0.06285 \n",
      "Epoch: 96, loss: 0.28372 valid loss:  0.06249 \n",
      "Epoch: 97, loss: 0.16939 valid loss:  0.06225 \n",
      "Epoch: 98, loss: 0.05505 valid loss:  0.06214 \n",
      "Epoch: 99, loss: 0.05507 valid loss:  0.06208 \n",
      "Epoch: 100, loss: 0.05511 valid loss:  0.06200 \n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(1, 3, 512, 2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr= 1e-3,weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=100,factor =0.5 ,min_lr=1e-7, eps=1e-08)\n",
    "for i in progress_bar(range(100)):\n",
    "    lstm.train()\n",
    "    output = lstm(X_train.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, y_train.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    lstm.eval()\n",
    "    valid = lstm(X_test.float())\n",
    "    val_loss = criterion(valid, y_test.float())\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f \" %(i + 1, loss.cpu().item(),val_loss.cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d93918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a68cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

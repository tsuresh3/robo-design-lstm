{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc7170f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fde4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f894ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNs(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout, is_sequence):\n",
    "        super(TCNs, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.is_sequence = is_sequence\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n",
    "        y1 = self.tcn(inputs)\n",
    "\n",
    "        # if we want output as the same length as the input\n",
    "        if self.is_sequence:\n",
    "            o = self.linear(y1.transpose(1, 2))\n",
    "\n",
    "        # if we only want the output from the last time step\n",
    "        else:\n",
    "            o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6aa313db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn = TCNs(2, 1, [2], 3, 0.2, True)\n",
    "history = 4\n",
    "tcn.train()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(tcn.parameters(), lr= 1e-3,weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=100,factor =0.5 ,min_lr=1e-7, eps=1e-08)\n",
    "f_lst = ['des_dx', 'x', 'dx', 'torque']\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0288d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(f):\n",
    "    df = pd.DataFrame([line.strip().split() for line in f.readlines()])\n",
    "    df = df[[0, 1, 3, 6]]\n",
    "    df.columns = f_lst\n",
    "    df['vel_error'] = df['des_dx'].astype(float) - df['dx'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b120de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(df, h = history):\n",
    "    X = np.array(df[['x', 'vel_error']]).astype('float')\n",
    "    \n",
    "    X = np.array([[[X[i - j][k] for j in range(h - 1, -1, -1)] for k in range(2)] for i in range(h - 1, len(X))])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #g = np.array([[[0, 0], [0, 0], X[0]], [[0, 0], X[0], X[1]]])\n",
    "    \n",
    "    #X = np.concatenate([g, X])\n",
    "    y = np.array(df[['torque']]).astype('float')[(h - 1):]\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b83a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/tarsur909/Documents/PythonStuff/data/data1.0.txt') as f:\n",
    "        df = create_df(f)\n",
    "\n",
    "X, y = create_xy(df)\n",
    "count = 1\n",
    "#for n in range(1, 100):\n",
    "lst = [i for i in range(1, 100)]\n",
    "sample = random.sample(lst, 99)\n",
    "train = []\n",
    "test = []\n",
    "for n in sample:\n",
    "    if count <= 36:\n",
    "        try: \n",
    "            with open('/Users/tarsur909/Documents/PythonStuff/data/data0.' + str(n) + '.txt') as f:\n",
    "                temp_df = create_df(f) \n",
    "            tempX, tempy = create_xy(temp_df)\n",
    "            X = np.concatenate([X, tempX])\n",
    "            y = np.concatenate([y, tempy])\n",
    "            train.append(n)\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        try: \n",
    "            with open('/Users/tarsur909/Documents/PythonStuff/data/data0.' + str(n) + '.txt') as f:\n",
    "                temp_df = create_df(f)\n",
    "            test.append(n)\n",
    "        except:\n",
    "            continue\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "292fd9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8734, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b71ef53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6987, 4, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "X_train = Variable(torch.tensor(X_train))\n",
    "output = tcn(X_train.float())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34c3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, epochs = 500, criterion = criterion, optimizer = optimizer, scheduler = scheduler):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    X_train = Variable(torch.tensor(X_train))\n",
    "    X_test = Variable(torch.tensor(X_test))\n",
    "    y_train = Variable(torch.tensor(y_train))\n",
    "    y_test = Variable(torch.tensor(y_test))\n",
    "    \n",
    "    for i in progress_bar(range(1, 501)):\n",
    "        model.train()\n",
    "        output = model(X_train.float())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(output, y_train.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lstm.eval()\n",
    "        valid = model(X_test.float())\n",
    "        val_loss = criterion(valid, y_test.float())\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "        if i == 1 or i % 50 == 0:\n",
    "            print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f \" %(i, loss.cpu().item(),val_loss.cpu().item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8778b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarsur909/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([6987, 1])) that is different to the input size (torch.Size([6987, 4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (6987) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X, y, epochs, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     12\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X_train\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (6987) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train(tcn, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bc3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.40% [7/500 00:37&lt;43:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.16403 valid loss:  0.16434 \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "X_train = Variable(torch.tensor(X_train))\n",
    "X_test = Variable(torch.tensor(X_test))\n",
    "y_train = Variable(torch.tensor(y_train))\n",
    "y_test = Variable(torch.tensor(y_test))\n",
    "    \n",
    "    \n",
    "for i in progress_bar(range(1, 501)):\n",
    "    lstm.train()\n",
    "    output = lstm(X_train.float())\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    loss = criterion(output, y_train.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    lstm.eval()\n",
    "    valid = lstm(X_test.float())\n",
    "    val_loss = criterion(valid, y_test.float())\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if i == 1 or i % 50 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f \" %(i, loss.cpu().item(),val_loss.cpu().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4558de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_predictions(data, title):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 12))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    fig.suptitle('Graphs for ' + title + ' Data')\n",
    "    \n",
    "    for n in data:\n",
    "        if i < 3:\n",
    "    \n",
    "            with open('/Users/tarsur909/Documents/PythonStuff/data/data' + str(format(n / 100.0, '.2f')) + '.txt') as f:\n",
    "                df = create_df(f)\n",
    "\n",
    "            X, y = create_xy(df)\n",
    "            lstm.eval()\n",
    "            X = Variable(torch.tensor(X))\n",
    "            whole = lstm(X.float())\n",
    "            whole = whole.detach().numpy()\n",
    "            whole = whole.flatten()\n",
    "            result = pd.DataFrame(data = {'predictions': whole, 'real': y.flatten()})\n",
    "    \n",
    "            sns.lineplot(ax = axes[i, j], data = result).set(title='Des Vel of ' + str(format(n / 100.0, '.2f')))\n",
    "    \n",
    "            j += 1\n",
    "            \n",
    "            if j > 2:\n",
    "                j = 0\n",
    "                i += 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95fe641b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36mgraph_predictions\u001b[0;34m(data, title)\u001b[0m\n\u001b[1;32m     11\u001b[0m     df \u001b[38;5;241m=\u001b[39m create_df(f)\n\u001b[1;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m create_xy(df)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mlstm\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mtensor(X))\n\u001b[1;32m     16\u001b[0m whole \u001b[38;5;241m=\u001b[39m lstm(X\u001b[38;5;241m.\u001b[39mfloat())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_predictions(test, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e80009",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predictions(train, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0113a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
